<!DOCTYPE html>
<html>

  <head>
  




  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> Lecture Videos - Deep Generative Models / Summer 2025 </title>
  <meta name="description" content="Lecture Videos - Deep Generative Models / Summer 2025">
  
  <link rel="stylesheet" href="/genai-utoronto/_css/main.css">
  <link rel="canonical" href="http://localhost:4000/genai-utoronto/lectures/">
  <link rel="alternate" type="application/rss+xml" title="Deep Generative Models / Summer 2025 - University of Toronto" href="http://localhost:4000/genai-utoronto/feed.xml" />
<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>




<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
<link rel="stylesheet" href="/genai-utoronto/assets/css/custom.css">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper" style="z-index: 100;">
      <table><tr>
          <td><img width="75" src="/genai-utoronto/_images/logo.png" valign="middle"></td>
          <td style="padding-left:10px;"><a class="schoolname" style="font-size: 15px; color: black;" class="site-title" href="https://www.ece.utoronto.ca">University of Toronto</a>
          <br/>
          <span class="site-title" style="font-size: 24px;font-weight: bold; color: black; display: block;">Deep Generative Models</span>
          <!-- <span style="color: black; margin-top: -2px;margin-bottom: -5px;" class="site-title" ><a href="/genai-utoronto/" title="Deep Generative Models / Summer 2025 - University of Toronto"><b>Deep Generative Models</a></b></span> -->
          <br/>
          <span class="coursesemeter" style="font-size: 15px;font-weight: bold;margin-top: 10px; color: black; display: block;">Summer 2025</span>
          </td>
        </tr></table>

    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#000000" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#000000" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#000000" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">
    
    <li>
        <a class="page-link" href="/genai-utoronto/">
            <i class="fa fa-home fa-lg"></i> Home
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/genai-utoronto/schedule/">
            <i class="fas fa-calendar-alt"></i> Schedule
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/genai-utoronto/lectures/">
            <i class="fas fa-video"></i> Lecture Videos
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/genai-utoronto/materials/">
            <i class="fas fa-book-reader"></i> Materials
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/genai-utoronto/assignments/">
            <i class="fas fa-book"></i> Assignments
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/genai-utoronto/project/">
            <i class="fas fa-user-graduate"></i> Project
        </a>
    </li>
    
</ul>

     </div>  
    </nav>

  </div>

  <!-- <div class="header-texture" style="height:100%; z-index: 0; position: absolute; top:0; right: 0; left: 0; 
  background-image: url('/genai-utoronto/_images/pattern.png');" /> -->

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Lecture Videos</h1>
  </header>

  <article class="post-content">
    <h1>Lectures</h1>
<p><p>Here, you can find the recordings of the lecture videos.</p>
</p>

<ul id="archive">














<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/PYVM7Ab9FXQ"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 0: Course Overview and Logistics</span><br>

        <strong> Overview: <em>This lecture gives an overview on the course structure and the logistics.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/PYVM7Ab9FXQ">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH0/CH0.pdf">Chapter 0</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/P7LGgmLU-8g"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 1: Tokenization and Embedding</span><br>

        <strong> LMs - Part 1: <em>We start with LMs and understand how we can feed a text into it by doing the so-called "Tokenization" and "Embedding".</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/P7LGgmLU-8g">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec1.pdf">Chapter 1 - Section 1</a> Pgs 1:18
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/2.pdf">Tokenization</a>: Chapter 2 of <a href="https://web.stanford.edu/~jurafsky/slp3/">[JM]</a></li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">Embedding</a>: Chapter 6 of <a href="https://web.stanford.edu/~jurafsky/slp3/">[JM]</a></li>
  <li><a href="http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM">Original BPE Algorithm</a>: Original BPE Algorithm proposed by Philip Gage in 1994</li>
  <li><a href="https://arxiv.org/abs/1508.07909">BPE for Tokenization</a>: Paper <em>Neural machine translation of rare words with subword units</em> by <em>Rico Sennrich, Barry Haddow, and Alexandra Birch</em> presented in ACL 2016 that adapted BPE for NLP</li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/Gy34u_0ARKc"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 2: Language Distribution and Bi-Gram Model</span><br>

        <strong> LMs - Part 2: <em>In this lecture, we define the LMs concretely via the notion of language distribution. We then build a simple Bi-gram LM.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/Gy34u_0ARKc">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec1.pdf">Chapter 1 - Section 1</a> Pgs 18:32
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">LMs</a>: Chapter 12 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Section 12.2</strong></li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-Gram LMs</a>: Chapter 3 of <em>Speech and Language Processing;</em> <strong>Section 3.1</strong> on N-gram LM</li>
  <li><a href="https://www.bishopbook.com/">Maximum Likelihood</a>: Chapter 2 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Sections 12.1 – 12.3</strong></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/uCAdDSf_ItQ"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 3: Recurrent LMs</span><br>

        <strong> LMs - Part 3: <em>This lecture explains how we can build a LM using RNNs. We take a look at LSTM-based LMs.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/uCAdDSf_ItQ">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec1.pdf">Chapter 1 - Section 1</a> Pgs 32:42
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/8.pdf">Recurrent LMs</a>: Chapter 8 of <a href="https://web.stanford.edu/~jurafsky/slp3/">[JM]</a></li>
  <li><a href="https://arxiv.org/abs/1708.02182">LSTM LMs</a>: Paper <em>Regularizing and Optimizing LSTM Language Models</em> by <em>Stephen Merity, Nitish Shirish Keskar, and Richard Socher</em> published in ICLR 2018 enabling LSTMs to perform strongly on word-level language modeling</li>
  <li><a href="https://arxiv.org/abs/1711.03953">High-Rank Recurrent LMs</a>: Paper <em>Breaking the Softmax Bottleneck: A High-Rank RNN Language Model</em> by <em>Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William W. Cohen</em> presented at ICLR 2018 proposing Mixture of Softmaxes (MoS) and achieving state-of-the-art results at the time</li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/R6eMENU9KDY"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 4: Context Extraction via Self-Attention</span><br>

        <strong> Transformer LMs - Part 1: <em>In this lecture we use self-attention mechanism to extract context from a token sequence. Introduction to self-attention is given through the lecture.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/R6eMENU9KDY">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec2.pdf">Chapter 1 - Section 2</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1706.03762">Transformer Paper</a>: Paper <strong>Attention Is All You Need!</strong> published in 2017 that made a great turn in sequence processing</li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf">Transformers</a>: Chapter 9 of <a href="https://web.stanford.edu/~jurafsky/slp3/">[JM]</a></li>
  <li><a href="https://www.bishopbook.com/">Transformers</a>: Chapter 12 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Section 12.1</strong></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/E7skNxn_4pI"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 5: Transformer LM</span><br>

        <strong> Transformer LMs - Part 2: <em>We use self-attention-based context to build a LM via a Transformer.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/E7skNxn_4pI">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec2.pdf">Chapter 1 - Section 2</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">Transformer LMs</a>: Chapter 12 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Section 12.3</strong></li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">LLMs via Transformers</a>: Chapter 10 of <a href="https://web.stanford.edu/~jurafsky/slp3/">[JM]</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/xWq9J27Xtdo"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 6: LLM Examples</span><br>

        <strong> LLMs - Part 1: <em>We take a look at GPT examples to see how deep they are, how large the data is, how to evaluate them, and what challenges are in the way of pre-training them.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/xWq9J27Xtdo">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec3.pdf">Chapter 1 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT-1</a>: Paper <em>Improving Language Understanding by Generative Pre-Training</em> by <em>Alec Radford et al.</em> (OpenAI, 2018) that introduced GPT-1 and revived the idea of pretraining transformers as LMs followed by supervised fine-tuning</li>
  <li><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>: Paper <em>Language Models are Unsupervised Multitask Learners</em> by <em>Alec Radford et al.</em> (OpenAI, 2019) that introduces GPT-2 with 1.5B parameter trained on web text</li>
  <li><a href="https://arxiv.org/abs/2005.14165">GPT-3</a>: Paper <em>Language Models are Few-Shot Learners</em> by <em>Tom B. Brown et al.</em> (OpenAI, 2020) that introduces GPT-3, a 175B-parameter transformer LM</li>
  <li>
    <p><a href="https://arxiv.org/abs/2303.08774">GPT-4</a>: <em>GPT-4 Technical Report</em> by <em>OpenAI</em> (2023) that provides an overview of GPT-4’s capabilities</p>
  </li>
  <li><a href="https://arxiv.org/abs/2101.00027">The Pile</a>: Paper <em>The Pile: An 800GB Dataset of Diverse Text for Language Modeling</em> by <em>Leo Gao et al.</em> presented in 2020 introductin dataset <strong>The Pile</strong></li>
  <li><a href="https://arxiv.org/abs/2105.05241">Documentation Debt</a>: Paper <em>Addressing “Documentation Debt” in Machine Learning Research: A Retrospective Datasheet for BookCorpus</em> by <em>Jack Bandy and Nicholas Vincent</em> published in 2021 discussing the efficiency and legality of data collection by looking into <a href="https://arxiv.org/abs/1511.06398">BookCorpus</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/ZKLvXfO_D6o"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 7: Pre-training vs Fine-tuning</span><br>

        <strong> LLMs - Part 2: <em>We discuss the idea of pre-training and fine-tuning, and take a look into the example of GPT-1.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/ZKLvXfO_D6o">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec3.pdf">Chapter 1 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1511.01432">SSL</a>: Paper <em>Semi-supervised Sequence Learning</em> by <em>Andrew M. Dai et al.</em> published in 2015 that explores using unsupervised pretraining followed by supervised fine-tuning; this was an early solid work advocating <strong>pre-training</strong> idea for LMs</li>
  <li><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT-1</a>: Paper <em>Improving Language Understanding by Generative Pre-Training</em> by <em>Alec Radford et al.</em> (OpenAI, 2018) that introduced GPT-1 and revived the idea of pretraining transformers as LMs followed by supervised fine-tuning</li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/F5EJkK4mJkU"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 8: Statistical View and LoRA</span><br>

        <strong> LLMs - Part 3: <em>We practice statistical view on the idea of fine-tuning, discuss full and selective fine-tuning, and study the low-rank adaptation (LoRA) method.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/F5EJkK4mJkU">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec3.pdf">Chapter 1 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">LMs</a>: Chapter 12 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Section 12.3.5</strong></li>
  <li><a href="https://arxiv.org/abs/2106.09685">LoRA</a>: Paper <em>LoRA: Low-Rank Adaptation of Large Language Models</em> by <em>Edward J. Hu et al.</em> presented at ICLR in 2022 introducing LoRA</li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/x2QrKlvzV00"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 9: Prompt Design</span><br>

        <strong> LLMs - Part 4: <em>In this lecture, we discuss the idea prompt design, i.e., using LLMs to sample directly from a task specific distribution. We get to overview ideas like "few-shot" and "zero-shot" learning and get to know what "foundation models" are.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/x2QrKlvzV00">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH1/CH1_Sec3.pdf">Chapter 1 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought</a>: Paper <em>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</em> by <em>Jason Wei et al.</em> presented at NeurIPS in 2022 introducing <strong>chain-of-thought</strong> prompting</li>
  <li><a href="https://arxiv.org/abs/2101.00190">Prefix-Tuning</a>: Paper <em>Prefix-Tuning: Optimizing Continuous Prompts for Generation</em> by <em>Xiang Lisa Li et al.</em> presented at ACL in 2021 proposing prefix-tuning approach for prompting</li>
  <li><a href="https://arxiv.org/abs/2104.08691">Prompt-Tuning</a>: Paper <em>The Power of Scale for Parameter-Efficient Prompt Tuning</em> by <em>B. Lester et al.</em> presented at EMNLP in 2021 proposing the prompt tuning idea, i.e., learning to prompt</li>
  <li><a href="https://arxiv.org/abs/2205.11916">Zero-Shot LLMs</a>: Paper <em>Large Language Models are Zero-Shot Reasoners</em> by <em>T. Kojima et al.</em> presented at NeurIPS in 2022 studying zero-shot learning with LLMs</li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/wRsQVKgG6J4"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 10: Data Generation Problem - Basic Definitions</span><br>

        <strong> Formulation - Part 1: <em>In this lecture, we start with the formulating the generic problem of data generation. We review the concept of "data distribution" and see that we essentially need to learn "how to sample from it".</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/wRsQVKgG6J4">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH2/CH2_Sec1.pdf">Chapter 2 - Section 1</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">Probabilistic Model</a>: Chapter 2 of <a href="https://www.bishopbook.com/">[BB]</a> <strong>Sections 2.4 to 2.6</strong></li>
  <li><a href="https://probml.github.io/pml-book/book2.html">Statistics</a>: Chapter 3 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a> <strong>Sections 3.1 to 3.3</strong></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/ilWOBFlLPjs"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 11: Discriminative vs Generative Learning</span><br>

        <strong> Formulation - Part 2: <em>In this lecture we study the discriminative and generative models. We see that many earlier computational models we learned are indeed discriminative. We further learn how we could use a generative model for a discriminative learning task.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/ilWOBFlLPjs">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH2/CH2_Sec2.pdf">Chapter 2 - Section 2</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">Discriminative and Generative Models</a>: Chapter 5 of <a href="https://www.bishopbook.com/">[BB]</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/6Td-PlpsOIY"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 12: Naive Bayes - Most Basic Generative Model</span><br>

        <strong> Formulation - Part 3: <em>This lecture investigates Naive Bayes, the most basic generative model we can think of. This model enables us understand the idea of generative modeling clearly.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/6Td-PlpsOIY">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH2/CH2_Sec3.pdf">Chapter 2 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2001.tb00465.x?casa_token=DH9SI9elEXQAAAAA%3AVgLUtFs8TJVMldMvLbOhXTuvkyubn3CDcSaE7xD9fe02YwcTwBik5fEpAY1SpcMvl0kJZuwHqrKbIA">Naive Bayes</a>: Paper <em>Idiot’s Bayes—Not So Stupid After All?</em> by <em>D. Hand and K. Yu</em> published at <em>Statistical Review</em> in 2001 discussing the efficiency of Naive Bayes for classification</li>
  <li><a href="https://proceedings.neurips.cc/paper/2001/hash/7b7a53e239400a13bd6be6c91c4f6c4e-Abstract.html">Naive Bayes vs Linear Regression</a>: Paper <em>On Discriminative vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes</em> by <em>A. Ng and M. Jordan</em> presented at <em>NeurIPS</em> in 2001 elaborating the data-efficiency efficiency of Naive Bayes and asymptotic superiority of Logistic Regression</li>
  <li><a href="https://probml.github.io/pml-book/book2.html">Generative Models – Overview</a>: Chapter 20 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a> <strong>Sections 20.1 to 20.3</strong></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/hsDZ5vJlx-k"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 13: Explicit Distribution Learning - Sampling</span><br>

        <strong> Explicit Methods - Part 1: <em>In this lecture, we start with "explicit learning methods"; the term we use to refer to approaches that learn data distribution explicitly. We see that direct sampling from them is not easy and we need to develop an structured modeling.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/hsDZ5vJlx-k">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec1.pdf">Chapter 3 - Section 1</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">Sampling Overview</a>: Chapter 14 of <a href="https://www.bishopbook.com/">[BB]</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Sampling</a> The book <em>Pattern Recognition and Machine Learning</em> by Christopher Bishop. Read <strong>Chapter 11</strong> to know about how challenging <em>sampling from a distribution</em> is</li>
  <li><a href="https://www.deeplearningbook.org/">Sampling Methods</a>: Chapter 17 of <a href="https://www.deeplearningbook.org/">[GYC]</a> <strong>Sections 17.1 and 17.2</strong></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/z9hLKfjTW8Q"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 14: Maximum Likelihood Learning</span><br>

        <strong> Explicit Methods - Part 2: <em>We discuss the general recipe for distribution learning, i.e., maximum likelihood estimation (MLE). We see that MLE essentially minimizes the estimated KL divergence between our model and the data distribution.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/z9hLKfjTW8Q">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec1.pdf">Chapter 3 - Section 1</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://probml.github.io/pml-book/book2.html">KL Divergence and MLE</a>: Chapter 5 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a> <strong>Sections 5.1 to 5.2</strong></li>
  <li><a href="https://www.deeplearningbook.org/">MLE</a>: Chapter 5 of <a href="https://www.deeplearningbook.org/">[GYC]</a> <strong>Section 5.5</strong></li>
  <li><a href="http://www.inference.org.uk/itprnn/book.pdf">Maximum Likelihood Learning</a> The book <em>Information Theory, Inference, and Learning Algorithms</em> by David MacKay which discusses MLE for clustering in <strong>Chapter 22</strong></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/7OX9cmYNIGI"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 15: Autoregressive Modeling</span><br>

        <strong> AR Models - Part 1: <em>This lecture talks about the idea of autoregressive (AR) modeling. We see that using this approach, we can design an efficient model for data distribution. The price that we pay though is slow generation.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/7OX9cmYNIGI">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec2.pdf">Chapter 3 - Section 2</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://probml.github.io/pml-book/book2.html">Autoregressive Models</a>: Chapter 22 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/HgVrYHLai_I"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 16: Computational AR Models</span><br>

        <strong> AR Models - Part 2: <em>This lectures goes through a general framework for developing a computational AR model. These models extract a masked content and compute a conditional distribution based on that. Generation in these model is always slow.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/HgVrYHLai_I">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec2.pdf">Chapter 3 - Section 2</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://probml.github.io/pml-book/book2.html">Autoregressive Models</a>: Chapter 22 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/5lHb6BWdIvI"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 17: PixelRNN</span><br>

        <strong> AR Models - Part 3: <em>In this lecture, we look at PixelRNN; a visual autoregressive model which builds context by recursion. We take a look at its training and sampling.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/5lHb6BWdIvI">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec3.pdf">Chapter 3 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1601.06759">PixelRNN and PixelCNN</a>: Paper <em>Pixel Recurrent Neural Networks</em> by <em>A. Oord et al.</em> presented at <em>ICML</em> in 2016 proposing PixelRNN and PixelCNN</li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/ejqfN3OsDhk"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 18: Masked AR Models - PixelCNN and ImageGPT</span><br>

        <strong> AR Models - Part 4: <em>This lecture goes through the idea of masked AR models. These models give us the benefit of parallel computation, and hence can be efficiently trained using Teacher-Forcing Training. We look into the examples of PixelCNN and ImageGPT. The former uses masked convolution to realize an AR model, while the latter use masked decoding.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/ejqfN3OsDhk">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec3.pdf">Chapter 3 - Section 3</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1601.06759">PixelRNN and PixelCNN</a>: Paper <em>Pixel Recurrent Neural Networks</em> by <em>A. Oord et al.</em> presented at <em>ICML</em> in 2016 proposing PixelRNN and PixelCNN</li>
  <li><a href="https://proceedings.mlr.press/v119/chen20s/chen20s.pdf">ImageGPT</a>: Paper <em>Generative Pretraining from Pixels</em> by <em>M. Chen et al.</em> presented at <em>ICML</em> in 2020 proposing ImageGPT</li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/WjxDgS8j6RY"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Lecture 19: Energy Based Models - Boltzmann Distribution</span><br>

        <strong> EBMs - Part 1: <em>This is the first lecture on EBMs. We talk about Boltzmann distribution and how we could use it to build a distribution model from an arbitrary computational model. We call such models EBMs.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/WjxDgS8j6RY">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Lecture Notes:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/Notes/CH3/CH3_Sec4.pdf">Chapter 3 - Section 4</a>
<!-- - [AplDL Notes: Recurent NNs](/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf) --></li>
</ul>

<p><strong>Further Reads:</strong></p>
<ul>
  <li><a href="https://www.bishopbook.com/">EBMs</a>: Chapter 24 of <a href="https://probml.github.io/pml-book/book2.html">[M]</a></li>
  <li><a href="https://www.deeplearningbook.org/">Partition Function and Normalizing</a>: Chapter 16 of <a href="https://www.deeplearningbook.org/">[GYC]</a> <strong>Section 16.2</strong></li>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/6796877">Universality of EBMs</a> Paper <em>Representational power of restricted Boltzmann machines and deep belief networks,</em> by <em>N. Le Roux and Y. Bengio</em> published at <em>Neural Computation</em> in 2008 elaborating the representational power of EBMs
*<a href="https://www.researchgate.net/profile/Raia-Hadsell/publication/200744586_A_tutorial_on_energy-based_learning/links/5694442c08aeab58a9a2e650/A-tutorial-on-energy-based-learning.pdf">Tutorial on EBMs</a> Survey <em>A Tutorial on Energy-Based Learning,</em> by <em>Y. LeCun et al.</em> published in 2006</li>
</ul>

        </div>
        
    </div>
</div>
</li>


</ul>

<h1>Review Lectures</h1>
<p>Here, you can find review lectures on some key deep learning topics. It is strongly suggested that you watch these videos to recap those key concepts, as they are frequently used in the course.</p>

<ul id="archive">


<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/S_dyjvxqnlU"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 1</span><br>

        <strong> Sequence Data: <em>This is a lecture on sequence data and RNNs.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/S_dyjvxqnlU">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_SeqData.pdf">AplDL Notes: Sequence Data</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_RNNs.pdf">AplDL Notes: Recurent NNs</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/4yPXCN83cUA"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 2</span><br>

        <strong> Deep RNNs and Gating: <em>This is a lecture on deep RNNs.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/4yPXCN83cUA">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_DeepRNNs1.pdf">AplDL Notes: RNNs</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_BRNNs.pdf">AplDL Notes: Bidirectional RNNs</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_CTC.pdf">AplDL Notes: CTC Algorithm</a></li>
  <li><a href="https://pdfs.semanticscholar.org/bba8/a2c9b9121e7c78e91ea2a68630e77c0ad20f.pdf">Simple Language Models by RNNs</a></li>
  <li><a href="https://arxiv.org/abs/1308.0850">Sequence Generation with RNNs</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/Lg1DsTBDem0"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 3</span><br>

        <strong> Seq2Seq: <em>A lecture on sequence to sequence models.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/Lg1DsTBDem0">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_Seq2Seq_LM.pdf">AplDL Notes: Basic Language Model</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_Seq2Seq_EncDec.pdf">AplDL Notes: Encoder-Decoder</a></li>
  <li><a href="https://arxiv.org/abs/1409.3215v3">Seq2Seq Learning Paper</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/_4weXZtDw5E"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 4</span><br>

        <strong> Attention: <em>A lecture on attention mechanism.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/_4weXZtDw5E">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_Attention.pdf">AplDL Notes: Attention Mechanism</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/agjyCMSKv_0"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 5</span><br>

        <strong> Transformers: <em>A lecture on self-attention and transformers.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/agjyCMSKv_0">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_Transformer.pdf">AplDL Notes: Self-Attention and Transformers</a></li>
  <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need!</a></li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf">Transformers - SLP CH9</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>



<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    <div style="text-align: center; margin-top: 0px; margin-bottom: 10px; margin-right: 20px;">
      <iframe width="250" height="150"
        src="https://www.youtube.com/embed/tcz-ctCzwyc"
        title="YouTube video player" frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div>
    <div class="content">
        <span style="font-weight: bold;">Review 6</span><br>

        <strong> Autoencoders: <em>An introduction to auto-encoding and its applications.</em></strong>
        <br/>
        <strong>
          [<a title="Download " href="https://youtu.be/tcz-ctCzwyc">link</a>]
        <!-- 
    
 -->
        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_nPCA.pdf">AplDL Notes: Nonlinear PCA</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_AEs.pdf">AplDL Notes: Autoencoders</a></li>
  <li><a href="/genai-utoronto/assets/AplDL/AplDL_VAE.pdf">AplDL Notes: Variational Autoencoders</a></li>
</ul>


        </div>
        
    </div>
</div>
</li>










































</ul>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

<!--     <h2 class="footer-heading">University of Toronto</h2> -->
         <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
 

         <p class="text">
The Edward S. Rogers Sr. Department of Electrical and Computer Engineering<br />
University of Toronto<br />

      </div>

      <div class="footer-col  footer-col-2">
       <ul class="social-media-list">
     

          

          
  <li>
    <a href="https://www.bereyhi.com">
      <i class="fas fa-globe" style="color:gray"></i> bereyhi.com
    </a>
  </li>


          

          

          
  <li>
    <a href="https://www.ece.utoronto.ca">
      <i class="fas fa-globe" style="color:gray"></i> ece.utoronto.ca
    </a>
  </li>




       
        </ul>
      </div>
    </div>

  </div>

</footer>

  </body>

</html>
<!-- d.s.m.s.050600.062508.030515.080516.030818 | "Baby, I'm Yours" -->